{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1decefa4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "current_dir = os.getcwd()\n",
        "parent_dir = os.path.dirname(current_dir)\n",
        "sys.path.append(parent_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "33a23e5b",
      "metadata": {
        "id": "33a23e5b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "_D_hUP1DYcWO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D_hUP1DYcWO",
        "outputId": "11d52cd7-8150-428a-c5d0-ead7032f7f0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 6, 8, 9])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "mask = torch.tensor([[True, True, True], [False, False, True], [False, True, True]])\n",
        "a[mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "id": "FxiNpG4AXqzy",
      "metadata": {
        "id": "FxiNpG4AXqzy"
      },
      "outputs": [],
      "source": [
        "def weighted_cross_entropy(pred_conf, target_conf, neg_weights=1e-3):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        pred_conf: (tensor) shape [batch_size, num_priors, num_classes]\n",
        "        target_conf: (tensor) shape [batch_size, num_priors]\n",
        "        neg_weights: (float)\n",
        "    Returns:\n",
        "        loss: (tensor) shape [1]\n",
        "    \"\"\"\n",
        "\n",
        "    # reshape them to [batch_size * num_priors, num_classes], [batch_Size * num_priors, -1]\n",
        "    pred_conf = pred_conf.view(-1, pred_conf.size(-1))\n",
        "    target_conf = target_conf.view(-1)\n",
        "    pos_mask = target_conf == 0\n",
        "    pred_conf = F.softmax(pred_conf, dim=-1)\n",
        "    target_conf = target_conf.long().unsqueeze(1)  # [N, 1]\n",
        "    nll = -torch.log(\n",
        "      pred_conf.gather(dim=1, index=target_conf)\n",
        "    ).squeeze(1)   # [N]\n",
        "    nll[pos_mask] = nll[pos_mask] * neg_weights\n",
        "    return nll.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f1f02d3",
      "metadata": {
        "id": "5f1f02d3"
      },
      "outputs": [],
      "source": [
        "from src.utils import matches\n",
        "class CustomMultiBoxLoss(nn.Module):\n",
        "    def __init__(self, threshold, priors, conf_weight = 1, neg_weight=1e-3):\n",
        "        super().__init__()\n",
        "        self.threshold = threshold\n",
        "        self.priors = priors\n",
        "        self.conf_weight = conf_weight\n",
        "        self.neg_weight = neg_weight\n",
        "\n",
        "    def encode(self, gt_list, matched_priors_boxes, variances=[0.1, 0.1, 0.2, 0.2]):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            gt_list: List of 1D tensors (absolute GT coords)\n",
        "            matched_priors_boxes: 2D tensor (corresponding anchor priors)\n",
        "        Returns:\n",
        "            List of 1D tensors (encoded offsets)\n",
        "        \"\"\"\n",
        "        if len(gt_list) == 0:\n",
        "            return []\n",
        "\n",
        "        matched_gt = torch.stack(gt_list)\n",
        "\n",
        "        g_cx = (matched_gt[:, 0] + matched_gt[:, 2]) / 2\n",
        "        g_cy = (matched_gt[:, 1] + matched_gt[:, 3]) / 2\n",
        "        g_w  = matched_gt[:, 2] - matched_gt[:, 0]\n",
        "        g_h  = matched_gt[:, 3] - matched_gt[:, 1]\n",
        "\n",
        "        p_cx = matched_priors_boxes[:, 0]\n",
        "        p_cy = matched_priors_boxes[:, 1]\n",
        "        p_w  = matched_priors_boxes[:, 2]\n",
        "        p_h  = matched_priors_boxes[:, 3]\n",
        "\n",
        "        # SSD Encoding Math\n",
        "        enc_cx = (g_cx - p_cx) / (p_w * variances[0])\n",
        "        enc_cy = (g_cy - p_cy) / (p_h * variances[1])\n",
        "        enc_w  = torch.log(g_w / p_w + 1e-5) / variances[2]\n",
        "        enc_h  = torch.log(g_h / p_h + 1e-5) / variances[3]\n",
        "\n",
        "        return torch.stack([enc_cx, enc_cy, enc_w, enc_h], dim=1)\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        \"\"\"\n",
        "            Args:\n",
        "                preds: (tuple) includes loc, conf\n",
        "                    loc: (tensor) shape [batch_size, num_priors, 4]\n",
        "                    conf: (tensor) shape [batch_size, num_priors, num_classes] (num_classes include background as 0)\n",
        "\n",
        "                targets: (list) shape [batch_size, num_object_i, 5]\n",
        "        \"\"\"\n",
        "        device = preds[0].device\n",
        "        pred_loc, pred_conf = preds\n",
        "\n",
        "        batch_size = pred_loc.size(0)\n",
        "        num_priors = pred_loc.size(1)\n",
        "\n",
        "        # loss matching\n",
        "        matched_priors, matched_gt_boxes = [], []\n",
        "        # create a tensor that has shape [batch_size, num_priors]\n",
        "        target_conf = torch.zeros((batch_size, num_priors))\n",
        "        for i in range(batch_size):\n",
        "            matched_gt_boxes_one = []\n",
        "            # calculate jaccard scores\n",
        "            truth_indexes = matches(self.threshold, torch.as_tensor(targets[i], device=device), self.priors)\n",
        "            match_priors_one = pred_loc[i][truth_indexes != -1] # match those doesn't predict bg\n",
        "            for truth_id in truth_indexes:\n",
        "                if truth_id != -1:\n",
        "                    matched_gt_boxes_one.append(torch.as_tensor(targets[i][truth_id], device=device)[:-1])\n",
        "            matched_priors.extend(match_priors_one)\n",
        "            matched_gt_boxes.extend(self.encode(matched_gt_boxes_one, self.priors[truth_indexes != -1]))\n",
        "\n",
        "            for j in range(num_priors):\n",
        "                target_conf[i, j] = targets[i][truth_indexes[j]][-1]\n",
        "        matched_priors = torch.cat(matched_priors, dim=0).to(device)\n",
        "        matched_gt_boxes = torch.cat(matched_gt_boxes, dim=0).to(device)\n",
        "\n",
        "        loc_loss = F.smooth_l1_loss(matched_priors, matched_gt_boxes, reduction='sum') / batch_size\n",
        "\n",
        "        # conf loss\n",
        "        target_conf = target_conf.to(device)\n",
        "        conf_loss = weighted_cross_entropy(pred_conf, target_conf, neg_weights=self.neg_weight) / batch_size * self.conf_weight\n",
        "\n",
        "\n",
        "        return loc_loss, conf_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b5db8c9",
      "metadata": {
        "id": "6b5db8c9"
      },
      "outputs": [],
      "source": [
        "from src.prior_box import PriorBox, voc\n",
        "prior_gen = PriorBox(voc)\n",
        "prior_boxes = prior_gen.forward()\n",
        "prior_boxes = prior_boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "id": "61e9d983",
      "metadata": {
        "id": "61e9d983"
      },
      "outputs": [],
      "source": [
        "loss_fn = CustomMultiBoxLoss(0.5, prior_boxes, conf_weight=10, neg_weight=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DV144HQxm0jv",
      "metadata": {
        "id": "DV144HQxm0jv"
      },
      "source": [
        "# AI TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "id": "a11deb59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a11deb59",
        "outputId": "5249f395-8164-4cfb-adc5-c58f48f8690b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Convergence Test ---\n",
            "Iter       | Loc Loss   | Conf Loss  | Total     \n",
            "----------------------------------------------\n",
            "0          | 3.1875     | 250.8980   | 254.0855  \n",
            "10         | 1.7884     | 0.0425     | 1.8309    \n",
            "20         | 0.3953     | 0.0019     | 0.3973    \n",
            "30         | 0.0319     | 0.0007     | 0.0326    \n",
            "40         | 0.0549     | 0.0005     | 0.0554    \n",
            "50         | 0.0262     | 0.0004     | 0.0266    \n",
            "60         | 0.0029     | 0.0004     | 0.0033    \n",
            "70         | 0.0010     | 0.0004     | 0.0014    \n",
            "80         | 0.0011     | 0.0004     | 0.0015    \n",
            "90         | 0.0003     | 0.0004     | 0.0007    \n",
            "----------------------------------------------\n",
            "Final Predictions Check:\n",
            "Prior 0 (Center) Class Probs: [0. 1. 0.]\n",
            "Prior 1 (Top-L)  Class Probs: [0. 0. 1.]\n",
            "Prior 2 (Bot-R)  Class Probs: [0. 0. 1.]\n",
            "\n",
            "Prior 0 Loc Offsets (Target ~0): [ 0.  0. -0. -0.]\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "def test_convergence():\n",
        "    print(\"--- Starting Convergence Test ---\")\n",
        "\n",
        "    # 1. Setup Data\n",
        "    # Fixed priors: (cx, cy, w, h)\n",
        "    priors = torch.tensor([\n",
        "        [0.5, 0.5, 0.2, 0.2], # Center anchor\n",
        "        [0.2, 0.2, 0.1, 0.1], # Top-left anchor\n",
        "        [0.8, 0.8, 0.1, 0.1]  # Bottom-right anchor\n",
        "    ], dtype=torch.float32)\n",
        "\n",
        "    # Ground Truth: One object in the middle (class 1), one top left (class 2)\n",
        "    # Format: [x1, y1, x2, y2, label]\n",
        "    target_data = [[\n",
        "        [0.4, 0.4, 0.6, 0.6, 1.0], # Matches prior 0 perfectly\n",
        "        [0.15, 0.15, 0.25, 0.25, 2.0] # Matches prior 1\n",
        "    ]]\n",
        "\n",
        "    # 2. Setup Model (Simulated)\n",
        "    # Pred Loc: [1 batch, 3 priors, 4 coords]\n",
        "    # Pred Conf: [1 batch, 3 priors, 3 classes (0=bg, 1, 2)]\n",
        "\n",
        "    # Initialize with random noise\n",
        "    pred_loc = torch.randn(1, 3, 4, requires_grad=True)\n",
        "    pred_conf = torch.randn(1, 3, 3, requires_grad=True)\n",
        "\n",
        "    optimizer = optim.SGD([pred_loc, pred_conf], lr=1e-2, momentum=0.9)\n",
        "    criterion = CustomMultiBoxLoss(threshold=0.5, priors=priors, conf_weight=100)\n",
        "\n",
        "    # 3. Training Loop\n",
        "    print(f\"{'Iter':<10} | {'Loc Loss':<10} | {'Conf Loss':<10} | {'Total':<10}\")\n",
        "    print(\"-\" * 46)\n",
        "\n",
        "    for i in range(100):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        preds = (pred_loc, pred_conf)\n",
        "        loss_l, loss_c = criterion(preds, target_data)\n",
        "        total_loss = loss_l + loss_c\n",
        "\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f\"{i:<10} | {loss_l.item():<10.4f} | {loss_c.item():<10.4f} | {total_loss.item():<10.4f}\")\n",
        "\n",
        "    # 4. Final Validation\n",
        "    print(\"-\" * 46)\n",
        "    print(\"Final Predictions Check:\")\n",
        "\n",
        "    # Check Confidence (Should classify Prior 0 as Class 1, Prior 1 as Class 2)\n",
        "    probs = F.softmax(pred_conf, dim=2)\n",
        "    print(\"Prior 0 (Center) Class Probs:\", probs[0, 0].detach().numpy().round(2))\n",
        "    print(\"Prior 1 (Top-L)  Class Probs:\", probs[0, 1].detach().numpy().round(2))\n",
        "    print(\"Prior 2 (Bot-R)  Class Probs:\", probs[0, 2].detach().numpy().round(2))\n",
        "\n",
        "    # Check Localization (Should be close to 0 offsets for perfect matches)\n",
        "    # Since GT matches Priors almost perfectly in this data, offsets should converge to 0\n",
        "    print(\"\\nPrior 0 Loc Offsets (Target ~0):\", pred_loc[0, 0].detach().numpy().round(2))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_convergence()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "78a52c42",
      "metadata": {
        "id": "78a52c42"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "digit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
