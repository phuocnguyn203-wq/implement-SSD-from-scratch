{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48fc628b",
   "metadata": {},
   "source": [
    "# Match function return indexes of gt boxes indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f305d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "721a86b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_form(boxes):\n",
    "    \"\"\"\n",
    "    Convert prior_boxes to (xmin, ymin, xmax, ymax)\n",
    "        args: \n",
    "            boxes: (tensor of shape (num_boxes, 4))\n",
    "            image_size: Size of square image\n",
    "        return:\n",
    "        boxes (tensor of shape (num_boxes, 4)) \n",
    "    \"\"\"\n",
    "    center  = boxes[:, :2]\n",
    "    align = boxes[:, 2:] / 2\n",
    "    top_left = center - align\n",
    "    bottom_right = center + align\n",
    "    \n",
    "    return torch.cat([top_left, bottom_right], dim=-1)\n",
    "\n",
    "def jaccard(priors, truths):\n",
    "    \"\"\"\n",
    "    calculate IoU of every default box with every gt box\n",
    "        args:\n",
    "            truths: tensor of shape (num_objects, 4)\n",
    "            priors: tensor of shape (8732,        4)\n",
    "    \"\"\"\n",
    "    # unsqueeze dim 0 of truths and dim 1 of priors to compare every box of priors with every box of truth\n",
    "    # both are broadcasted (num_priors, num_objects, 4)\n",
    "    num_priors = priors.size(0)\n",
    "    num_objects = truths.size(0)\n",
    "    truths = truths.unsqueeze(0).expand(num_priors, -1, -1)\n",
    "    priors = priors.unsqueeze(1).expand(-1, num_objects, -1)\n",
    "    x1y1 = torch.max(truths[..., :2], priors[..., :2])\n",
    "    x2y2 = torch.min(truths[..., 2:], priors[..., 2:])\n",
    "    inter_area = (x2y2 - x1y1).clamp(min=0).prod(dim=-1)\n",
    "    truth_area = (truths[..., 2] - truths[..., 0]) * (truths[..., 3] - truths[..., 1])\n",
    "    prior_area = (priors[..., 2] - priors[..., 0]) * (priors[..., 3] - priors[..., 1])\n",
    "    eps = 1e-7\n",
    "    return inter_area / (prior_area + truth_area - inter_area + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "decb50d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(threshold, truths, priors):\n",
    "    \"\"\"\n",
    "        return a 1d Tensor, ith position is the index of gt boxes\n",
    "        match with i-th prior box \n",
    "        Args:\n",
    "            truths: (tensor) shape [num_objects, 5] (xmin, ymin, xmax, ymax, labels)\n",
    "            priors: (tensor) shape [num_priors, 4] (cx, cy, h, w)\n",
    "    \"\"\"\n",
    "    truths = truths[..., :-1]\n",
    "    \n",
    "    overlaps = jaccard(point_form(priors), truths)\n",
    "    \n",
    "    best_gt_scores, best_gt_indexes = overlaps.max(dim=1)\n",
    "    \n",
    "    best_prior_scores, best_prior_indexes = overlaps.max(dim=0)\n",
    "    \n",
    "    #this guarantees each gt box has atleast matches 1 prior box \n",
    "    for k in range(best_prior_indexes.size(0)):\n",
    "        best_gt_scores[best_prior_indexes[k]] = 2.0\n",
    "        best_gt_indexes[best_prior_indexes[k]] = k\n",
    "    best_gt_indexes = best_gt_indexes + 1\n",
    "    #take only those with scores above threshold value\n",
    "    best_gt_indexes[best_gt_scores < threshold] = 0 # 0 means background\n",
    "    \n",
    "    return best_gt_indexes\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95fc82ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "truths = torch.tensor([\n",
    "        [0.1, 0.1, 0.4, 0.4, 1],\n",
    "        [0.6, 0.6, 0.9, 0.9, 2], \n",
    "    ])\n",
    "\n",
    "priors = torch.tensor([\n",
    "    [0.25, 0.25, 0.3, 0.3],\n",
    "    [0.75, 0.75, 0.3, 0.3],\n",
    "    [0.50, 0.50, 0.2, 0.2],\n",
    "    [0.10, 0.90, 0.2, 0.2],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "455c7e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = jaccard(point_form(priors), truths[..., :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46934455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000],\n",
       "        [0.0000, 1.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d5fbb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1.0000, 1.0000, 0.0000, 0.0000]),\n",
       "indices=tensor([0, 1, 0, 0]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02226c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
